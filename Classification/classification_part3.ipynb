{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "rawdata=[\n",
    "['sunny',85,85,'FALSE',0],\n",
    "['sunny',80,90,'FALSE',0],\n",
    "['overcast',83,86,'TRUE',1],\n",
    "['rainy',70,96,'FALSE',1],\n",
    "['rainy',68,80,'FALSE',1],\n",
    "['rainy',65,70,'TRUE',0],\n",
    "['overcast',64,65,'TRUE',1],\n",
    "['sunny',72,95,'TRUE',0],\n",
    "['sunny',69,70,'FALSE',1],\n",
    "['rainy',75,80,'FALSE',1],\n",
    "['sunny',75,70,'TRUE',1],\n",
    "['overcast',72,90,'TRUE',1],\n",
    "['overcast',81,75,'FALSE',1],\n",
    "['rainy',71,91,'FALSE',0],\n",
    "['sunny',84,85,'FALSE',1],\n",
    "['sunny',81,89,'TRUE',1],\n",
    "['overcast',84,87,'FALSE',0],\n",
    "['rainy',72,95,'TRUE',0],\n",
    "['rainy',70,82,'FALSE',0],\n",
    "['rainy',63,71,'TRUE',1],\n",
    "['overcast',65,75,'TRUE',0],\n",
    "['sunny',74,93,'FALSE',1],\n",
    "['sunny',70,75,'FALSE',0],\n",
    "['rainy',80,79,'FALSE',0],\n",
    "['sunny',80,75,'TRUE',0],\n",
    "['overcast',75,85,'TRUE',0],\n",
    "['overcast',85,80,'FALSE',0],\n",
    "['rainy',75,91,'TRUE',1],\n",
    "\n",
    "    \n",
    "['rainy',80,80,'FALSE',1],\n",
    "['sunny',75,68,'FALSE',0],\n",
    "['sunny',80,90,'TRUE',0],\n",
    "['overcast',90,94,'TRUE',1],\n",
    "['rainy',85,96,'FALSE',1],\n",
    "['rainy',92,65,'TRUE',1],\n",
    "['rainy',69,79,'FALSE',0],\n",
    "['overcast',69,80,'TRUE',1],\n",
    "['sunny',78,92,'FALSE',0],\n",
    "['sunny',79,89,'TRUE',1],\n",
    "['rainy',91,99,'FALSE',1],\n",
    "['sunny',90,85,'TRUE',1],\n",
    "['overcast',89,86,'FALSE',1],\n",
    "['overcast',93,88,'TRUE',1],\n",
    "['rainy',76,93,'TRUE',0]\n",
    "]\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import SQLContext,Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "data_df=sqlContext.createDataFrame(rawdata,\n",
    "   ['outlook','temp','humid','windy','play'])\n",
    "\n",
    "#transform categoricals into indicator variables\n",
    "out2index={'sunny':[1,0,0],'overcast':[0,1,0],'rainy':[0,0,1]}\n",
    "\n",
    "#make RDD of labeled vectors\n",
    "def newrow(dfrow):\n",
    "    outrow = list(out2index.get((dfrow[0])))  #get dictionary entry for outlook\n",
    "    outrow.append(dfrow[1])   #temp\n",
    "    outrow.append(dfrow[2])   #humidity\n",
    "    if dfrow[3]=='TRUE':      #windy\n",
    "        outrow.append(1)\n",
    "    else:\n",
    "        outrow.append(0)\n",
    "    return (LabeledPoint(dfrow[4],outrow))\n",
    "\n",
    "datax_rdd=data_df.rdd.map(newrow)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = datax_rdd.randomSplit([0.7, 0.3],1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbmodel = NaiveBayes.train(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test =[]\n",
    "for i in range(test.count()):\n",
    "    predict_test.append(nbmodel.predict(test_data[:][i].features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [1.0,0.0,0.0,80.0,90.0,0.0]),\n",
       " LabeledPoint(0.0, [0.0,0.0,1.0,71.0,91.0,0.0]),\n",
       " LabeledPoint(1.0, [1.0,0.0,0.0,84.0,85.0,0.0]),\n",
       " LabeledPoint(1.0, [1.0,0.0,0.0,81.0,89.0,1.0]),\n",
       " LabeledPoint(0.0, [0.0,1.0,0.0,84.0,87.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,0.0,1.0,63.0,71.0,1.0]),\n",
       " LabeledPoint(0.0, [0.0,1.0,0.0,65.0,75.0,1.0]),\n",
       " LabeledPoint(0.0, [0.0,0.0,1.0,80.0,79.0,0.0]),\n",
       " LabeledPoint(1.0, [0.0,1.0,0.0,69.0,80.0,1.0]),\n",
       " LabeledPoint(1.0, [0.0,1.0,0.0,89.0,86.0,0.0])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.collect()\n",
    "predict_train =[]\n",
    "for i in range(train.count()):\n",
    "    predict_train.append(nbmodel.predict(train_data[:][i].features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = [ [0,0],[0,0] ]\n",
    "for i in range(train.count()):\n",
    "    conf_mat[int(train_data[:][i].label)][int(predict_train[i])] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6, 8], [4, 15]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracy = float((conf_mat[0][0] + conf_mat[1][1]) / train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.63636363636363"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracy * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Misclassification = float((conf_mat[0][1] + conf_mat[1][0]) /  train.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.36363636363637"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Misclassification * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_test = [[0,0],[0,0]]\n",
    "for j in range(test.count()):\n",
    "    conf_mat_test[int(test_data[:][j].label)][int(predict_test[j])] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4], [2, 3]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracy = float((conf_mat_test[0][0] + conf_mat_test[1][1]) / test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracy *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Misclassification = float((conf_mat_test[0][1] + conf_mat_test[1][0]) / test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Misclassification * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier_b024a121c96e"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=5,\n",
    "                            minInstancesPerNode=20, impurity='entropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTree.trainClassifier(datax_rdd, numClasses=2,categoricalFeaturesInfo={},\n",
    "                                          minInstancesPerNode=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test_tree =[]\n",
    "for i in range(test.count()):\n",
    "    predict_test_tree.append(tree_model.predict(test_data[:][i].features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train_tree = []\n",
    "for i in range(train.count()):\n",
    "    predict_train_tree.append(tree_model.predict(train_data[:][i].features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_tree = [ [0,0],[0,0] ]\n",
    "for i in range(train.count()):\n",
    "    conf_mat_tree[int(train_data[:][i].label)][int(predict_train_tree[i])] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 0], [11, 8]]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666666"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracy = float((conf_mat_tree[0][0] + conf_mat_tree[1][1]) / train.count()) * 100\n",
    "acuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_tree2 = [ [0,0],[0,0] ]\n",
    "for i in range(test.count()):\n",
    "    conf_mat_tree2[int(test_data[:][i].label)][int(predict_test_tree[i])] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 0], [3, 2]]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_mat_tree2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acuracy = float((conf_mat_tree2[0][0] + conf_mat_tree2[1][1]) / test.count()) * 100\n",
    "acuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
